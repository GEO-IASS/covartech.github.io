
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Feature Selection - prtFeatSelSfs - PRT Blog</title>
  <meta name="author" content="Kenneth Morton and Peter Torrione">

  
  <meta name="description" content="Feature Selection - prtFeatSelSfs Mar 19th, 2013 Today I&#8217;d like to take a look at using a particular approach to feature selection in the PRT &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://newfolder.github.io/blog/2013/03/19/feature-selection">
  <link href="/favicon.ico" rel="icon">
  
  <link href="/assets/bootstrap/css/spacelab.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/custom.css" rel="stylesheet" type="text/css">
  <link href="/assets/font-awesome/css/font-awesome.css" rel="stylesheet" type="text/css">
  
  <link href="/atom.xml" rel="alternate" title="PRT Blog" type="application/atom+xml">
  <style type="text/css">
pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
</style>
  

</head>

<body    data-spy="scroll">

  <div class="container">
    <header class="jumbotron subhead" id="overview">
      
<div class="subscribe">
  <table>
    <tr>
      <td><span>Get Updates: &nbsp;</span></td>
      
      
      <td><a href="/atom.xml" class="btn"><i class="icon-cog"></i> By RSS</a></td>
      
      
    </tr>
  </table>
</div>

<h1 class="title">PRT Blog</h1>

  <p class="lead">MATLAB Pattern Recognition Open Free and Easy</p>


      <div class="navbar">
  <div class="navbar-inner">
    <div class="container" style="width: auto;">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <div class="nav-collapse">
                <ul class="nav">
          <li><a href="/">Home</a></li>
          <li><a href="/blog/archives">Blog</a></li>
          <li><a href="https://github.com/newfolder/PRT">Code</a></li>
          <li><a href="/prtdoc/">Documentation</a></li>
		  <li><a href="https://github.com/newfolder/PRT/issues">Get Help</a><li>
          <li><a href="/about">About</a></li>
        </ul>

        
          <form action="http://google.com/search" method="get" class="navbar-search pull-left">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:newfolder.github.io" />
              <input type="text" name="q" results="0" placeholder="Search" class="search-query span2" />
            </fieldset>
          </form>
        
        
      </div><!-- /.nav-collapse -->
    </div>
  </div><!-- /navbar-inner -->
</div>

    </header>
    <div id="main">
      <div id="content">
        <div class="row">
  
  <div class="span8">
    <br>

  <header>
    
      <h1 class="entry-title">Feature Selection - prtFeatSelSfs</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-19T21:58:00-04:00" pubdate data-updated="true">Mar 19<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Today I&#8217;d like to take a look at using a particular approach to feature selection in the PRT, and how that can be used to perform dimension reduction.  The approach we&#8217;ll use is called &#8220;sequential forward search&#8221;, and is implemented in prtFeatSelSfs.</p>


<!--/introduction-->


<h2>Contents</h2>


<div><ul><li><a href="#1">Some Data</a></li><li><a href="#3">Feature Selection</a></li><li><a href="#4">Defining &#8220;Informative&#8221;</a></li><li><a href="#7">Conclusions</a></li></ul></div>


<h2>Some Data<a name="1"></a></h2>


<p>The PRT comes with a utility function to generate data that has about 10 features, and for which only 5 of the features are actually informative. The function is prtDataGenFeatureSelection, I&#8217;ll let the help entry explain how it works:</p>


<pre class="codeinput">help <span class="string">prtDataGenFeatureSelection</span>
</pre>


<pre class="codeoutput"> prtDataGenFeatureSelection   Generates some unimodal example data for the prt.
   DataSet = prtDataGenFeatureSelection
   The data is distributed:
        H0: N([0 0 0 0 0 0 0 0 0 0],eye(10))
        H1: N([0 2 0 1 0 2 0 1 0 2],eye(10))
 
  Syntax: [X, Y] = prtDataGenFeatureSelection(N)
 
  Inputs: 
        N ~ number of samples per class (200)
 
  Outputs:
    X - 2Nx2 Unimodal data
    Y - 2Nx1 Class labels
 
  Example:
    DataSet = prtDataGenFeatureSelection;
    explore(DataSet)
 
  Other m-files required: none
  Subfunctions: none
  MAT-files required: none
 
  See also: prtDataGenUnimodal

</pre>


<p>As you can see from the help, only dimensions 2, 4, 6, 8, and 10 are actually informative in this data set.  And we can use feature selection to help us pick out what features are actually useful.</p>


<h2>Feature Selection<a name="3"></a></h2>


<p>Feature selection objects are prefaced in the prt with prtFeatSel*, and they act just like any other prtAction objects.  During training a feature selection action will typically perform some iterative search over the feature space, and determine which features are most informative.  At run-time, the same object will return a prtDataSet containing onlt the features the algorithm considered &#8220;informative&#8221;.</p>


<p>For example:</p>


<pre class="codeinput">ds = prtDataGenFeatureSelection;
featSel = prtFeatSelSfs;
featSel = featSel.train(ds);
dsFeatSel = featSel.run(ds);

plot(dsFeatSel);
title(<span class="string">'Three Most Informative Features'</span>);
</pre>


<p><img vspace="5" hspace="5" src="/images/torrione_ExampleFeatureSelection_01.png" alt=""> <h2>Defining &ldquo;Informative&rdquo;<a name="4"></a></h2><p>How does the feature selection algorithm determine what features are informative?  For many (but not necessarily all) feature selection objects, the interesting field is &ldquo;evaluationMetric&rdquo;.</p><p>Let&rsquo;s take a look:</p><pre class="codeinput">featSel.evaluationMetric
</pre><pre class="codeoutput">
ans =</p>

<pre><code>@(DS)prtEvalAuc(prtClassFld,DS)
</code></pre>

<p></pre><p>Obviously, evaluationMetric is a function handle &ndash; in particular it represents a call to a prtEval<em> method.  prtEval</em> methods typically take 2 or 3 input arguments &ndash; a classifier to train and run, a data set to train and run on, and (optionally) a number of folds (or fold specification) to use for cross-validation.</p><p>Feature selection objects iteratively search through the features available &ndash; in this case, all 10 of them, and apply the prtEval* method to the sub-sets of data formed by retaining a sub-set of the available features.  The exact order in which the features are retained and removed depends on the feature selection approach &ndash; in SFS, the algorithm first iteratively searches through the features &ndash; 1,2,3&hellip;,10.  Then it remembers which single feature provided the best performance &ndash; say it was feature 2.  Next, the SFS algorithm iteratively searches through all 9 combinations of other features with feature 2:    { {1,2},{3,2},{4,2},&hellip;,{10,2}} And remembers which of <b>those</b> performed best.  This process is iterated, and features continually added to the set being evaluated until nFeatures are selected.</p><p>The resulting performance is then stored in &ldquo;performance&rdquo;, and the features selected are stored in &ldquo;selectedFeatures&rdquo;.  Let&rsquo;s force the SFS approach to look for 10 features (so it will eventually select all of them).</p><pre class="codeinput">ds = prtDataGenFeatureSelection;
featSel = prtFeatSelSfs;
featSel.nFeatures = ds.nFeatures;
featSel.evaluationMetric = @(DS)prtEvalAuc(prtClassFld,DS,3);
featSel = featSel.train(ds);</p>

<p>h = plot(1:ds.nFeatures,featSel.performance);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
set(gca,<span class="string">&lsquo;xtick&rsquo;</span>,1:ds.nFeatures);
set(gca,<span class="string">&lsquo;xticklabel&rsquo;</span>,featSel.selectedFeatures);
xlabel(<span class="string">&lsquo;Features Selected&rsquo;</span>);
title(<span class="string">&lsquo;AUC vs. Features Selected&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_ExampleFeatureSelection_02.png" alt=""> <p>The features that get selected tend to favor features 2,6, and 10, then features 4 and 8, which makes sense as these are the 3 most informative followed by the two moderately-informative features!</p><h2>Conclusions<a name="7"></a></h2><p>There are a number of prtFeatSel<em> actions available, but not as many as we&rsquo;d like.  We&rsquo;re constantly on the look-out for new ones, and we&rsquo;d like to one day include &ldquo;K-forward, L-Backward&rdquo; searches, but just haven&rsquo;t had the time recently.</p><p>Also, this example only used prtEvalAuc as the performance metric, but there are a number of prtEval</em> functions you can use, or, of course &ndash; feel free to write your own!</p><p>Take a look at prtEvalAuc to see how they work and how to create your own!</p><p>Enjoy!</p></p>
</div>


<br>
<hr>
<br>
    <footer>
      <p class="meta">
        
  

<span class="byline author vcard">Posted by <span class="fn">Pete</span></span>

        








  


<time datetime="2013-03-19T21:58:00-04:00" pubdate data-updated="true">Mar 19<span>th</span>, 2013</time>
        


      </p>
      
        <div class="sharing">
  <br/>
  
  
  
</div>

      
      <p class="meta">
        
          <a class="basic-alignment pull-left" href="/blog/2013/03/10/max-pooling/" title="Previous Post: Max-Pooling Feature Representations in MSRCORID">&laquo; Max-Pooling Feature Representations in MSRCORID</a>
        
        
          <a class="basic-alignment pull-right" href="/blog/2013/03/24/rvs-part-2/" title="Next Post: RVs Part 2 - Mixture Models">RVs Part 2 - Mixture Models &raquo;</a>
        
      </p>
    </footer>
    
    
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
      </section>
    
  </div>

  
    
  <div class="span3 sidebar">
    <div class="well">
      
        <section>
  <h2>Recent Posts</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/06/24/spectral-clustering/">Spectral Clustering</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/13/prtclustermeanshift/">prtClusterMeanShift</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/03/using-k-means-as-a-feature-extractor/">Using K-Means As a Feature Extractor</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/21/new-visualization-with-imagesc/">New Visualization with IMAGESC</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/15/prtdatagensandp500-and-prtdatagencylinderbellfunnel/">prtDataGenSandP500 and prtDataGenCylinderBellFunnel</a>
      </li>
    
  </ul>
</section>


      
    </div>
  </div>


  
</div>


      </div>
    </div>
    <footer class="footer"><p>
  Copyright &copy; 2013 - Kenneth Morton and Peter Torrione -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  
    <span class="credit">Theme by <a href="http://brianarmstrong.org">Brian Armstrong</a></span>
  
</p>
</footer>
    

<script type="text/javascript">
      var disqus_shortname = 'newfolderconsulting';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://newfolder.github.io/blog/2013/03/19/feature-selection/';
        var disqus_url = 'http://newfolder.github.io/blog/2013/03/19/feature-selection/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="/assets/bootstrap/js/bootstrap.min.js"></script>


  </div>
</body>
</html>
