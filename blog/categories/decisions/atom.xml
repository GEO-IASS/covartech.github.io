<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Decisions | PRT Blog]]></title>
  <link href="http://newfolder.github.io/blog/categories/decisions/atom.xml" rel="self"/>
  <link href="http://newfolder.github.io/"/>
  <updated>2013-06-24T09:10:52-04:00</updated>
  <id>http://newfolder.github.io/</id>
  <author>
    <name><![CDATA[Kenneth Morton and Peter Torrione]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Decisions Decisions]]></title>
    <link href="http://newfolder.github.io/blog/2013/01/25/decisions-decisions/"/>
    <updated>2013-01-25T10:45:00-05:00</updated>
    <id>http://newfolder.github.io/blog/2013/01/25/decisions-decisions</id>
    <content type="html"><![CDATA[<p>You may have noticed in a lot of examples, we've made use of prtDecision objects, and might have wondered what exactly those are, and how they work.  Today I'd like to describe the prtDecision* actions, and when you might want to use them.</p>


<!--/introduction-->


<h2>Contents</h2>


<div><ul><li><a href="#4">Making Manual Decisions</a></li><li><a href="#8">Decision Objects</a></li><li><a href="#11">Concluding</a></li></ul></div>


<p>Let's start out with a pretty standard prtDataSet, and we'll make a classifier and score a ROC curve:</p>


<pre class="codeinput">ds = prtDataGenUnimodal;
classifier = prtClassFld;
yOutFld = kfolds(classifier,ds,3);
[pf,pd] = prtScoreRoc(yOutFld);
h = plot(pf,pd);
set(h,<span class="string">'linewidth'</span>,3);
title(<span class="string">'ROC Curve for FLD'</span>);
xlabel(<span class="string">'Pfa'</span>);
ylabel(<span class="string">'Pd'</span>);
</pre>


<p><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_01.png" alt=""> <p>That ROC curve looks pretty good, but it doesn&rsquo;t tell the whole story. At the end of the day, if you wanted to use your FLD algorithm in a production setting, you&rsquo;ll need to make discrete decisions to take different actions depending on whether you&rsquo;re calling something Class #1 or Class #0.  An ROC curve is suitable for comparing performance across a range of possible operating points, but what if we wanted to know exactly what PD and PFA we were going to get for a particular decision point?</p><p>To clarify matters, let&rsquo;s take a look at what the output from FLD actually looks like.</p><pre class="codeinput">h = plot(1:yOutFld.nObservations,yOutFld.X,1:yOutFld.nObservations,yOutFld.Y);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
xlabel(<span class="string">&lsquo;Observation Index&rsquo;</span>);
legend(h,{<span class="string">&lsquo;FLD Output&rsquo;</span>,<span class="string">&lsquo;Class Label&rsquo;</span>});
title(<span class="string">&lsquo;FLD Output &amp; Actual Class Label vs. Observation Index&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_02.png" alt=""> <p>The above figure shows what&rsquo;s actually going on under the hood &ndash; when a classifier object is run on a data set, the output data set (yOutFld) has it&rsquo;s X value set to the classifier output.  In this case, the yOutFld.X value is a linear weighting of the input variables, and is shown in blue.  You can see how it correlated with the actual class labels (in green).</p><h2>Making Manual Decisions<a name="4"></a></h2><p>Say we wanted to make decisions based on the output of the FLD.  We have to choose a threshold (a point along the y-axis) such that whenever a blue data point is above the threshold, we call the output &ldquo;Class 1&rdquo;, and otherwise we call it &ldquo;Class 0&rdquo;.  By visual inspection, any value between, say, 0 and 2 looks reasonable.  Let&rsquo;s try manually setting a threshold of 1:</p><pre class="codeinput">yOutManual = yOutFld;
yOutManual.X = yOutManual.X &gt; 1;
h = plot(1:yOutManual.nObservations,yOutManual.X,1:yOutManual.nObservations,yOutManual.Y);
ylim([&ndash;.1 1.1]);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
xlabel(<span class="string">&lsquo;Observation Index&rsquo;</span>);
legend(h,{<span class="string">&lsquo;Manual Decision Output&rsquo;</span>,<span class="string">&lsquo;Class Label&rsquo;</span>},4);
title(<span class="string">&lsquo;Manual Decision &amp; Actual Class Label vs. Observation Index&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_03.png" alt=""> <p>You can see that our chosen threshold does pretty well.  The vast majority of the time, the blue line corresponds to the green line.  We can confirm this by considering the percent correct, and a confusion matrix:</p><pre class="codeinput">prtScoreConfusionMatrix(yOutManual);
pc = prtScorePercentCorrect(yOutManual);
title(sprintf(<span class="string">&lsquo;Percent Correct: %.0f%%&rsquo;</span>,pc<em>100));
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_04.png" alt=""> <p>98% Correct!  That&rsquo;s not bad.  But look at what happens if we try and do the same scoring on the original output from the FLD:</p><pre class="codeinput">prtScoreConfusionMatrix(yOutFld);
pc = prtScorePercentCorrect(yOutFld);
title(sprintf(<span class="string">&lsquo;Percent Correct: %.0f%% (This is clearly wrong!)&rsquo;</span>,pc</em>100));
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_05.png" alt=""> <p>What happened?  This is a little subtle, but whenever the PRT has to score discrete classes, like with prtScorePercentCorrect and prtScoreConfusionMatrix, it requires that the X values in the dataset to be equal to your best guess as to the real underlying class.</p><p>That worked out great for yOutManual, since we set yOutManual.X to zero for class 0, and 1 for class 1.  But yOutFld has continuous values stored in it (as the earlier figure shows); you need to make discrete decisions for prtScorePercentCorrect or prtScoreConfusionMatrix to make any sense.</p><h2>Decision Objects<a name="8"></a></h2><p>Fortunately, the PRT provides a special kind of prtAction &ndash; prtDecisions to make those decisions for you automaticaly, so you can score algorithms very easily.</p><p>For example, prtDecisionBinaryMinPe tries to find a threshold based on the training data to minimize the probability of error (Pe). You can use the decision actions like you would use any other actions in a prtAlgorithm:</p><pre class="codeinput">algo = prtClassFld + prtDecisionBinaryMinPe;
yOutDecision = kfolds(algo,ds,3);
prtScoreConfusionMatrix(yOutDecision);
pc = prtScorePercentCorrect(yOutDecision);
title(sprintf(<span class="string">&lsquo;Percent Correct: %.0f%%&rsquo;</span>,pc<em>100));
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_06.png" alt=""> <p>Now we&rsquo;re back in the ball game!  You can use different decision objects to get performance at different points on the ROC curve, for example prtDecisionBinarySpecifiedPd let&rsquo;s you specify a Pd to operate at:</p><pre class="codeinput">close <span class="string">all</span>;
algo = prtClassFld + prtDecisionBinarySpecifiedPd(<span class="string">&lsquo;pd&rsquo;</span>,.99);
yOutDecision = kfolds(algo,ds,3);
prtScoreConfusionMatrix(yOutDecision);
pc = prtScorePercentCorrect(yOutDecision);
title(sprintf(<span class="string">&lsquo;Percent Correct: %.0f%%&rsquo;</span>,pc</em>100));
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_07.png" alt=""> <p>Note that the overall probability of error is significantly worse, but almost all of the data from Class 1 was identified as Class 1.  (This may not acheive 99% Pd in some cases since the thresholds are learned differently in each fold, so there is some statistical varition in the actual Pd acheived).</p><p>We can also use prtDecisionMap to perform multi-class decision making. The &ldquo;Map&rdquo; in prtDecisionMap stands for maximum a-posteriori.  This basically means &ldquo;decide the class corresponding to the maximum classifier output&rdquo;.</p><pre class="codeinput">ds = prtDataGenMary;
algo = prtClassKnn + prtDecisionMap;
yOutDecision = kfolds(algo,ds,3);
prtScoreConfusionMatrix(yOutDecision);
pc = prtScorePercentCorrect(yOutDecision);
title(sprintf(<span class="string">&lsquo;Percent Correct: %.0f%%&rsquo;</span>,pc*100));
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_Decisions_08.png" alt=""> <h2>Concluding<a name="11"></a></h2><p>So, there you go!  prtDecision objects handle a lot of book-keeping internally, so that you don&rsquo;t generally have to worry about making sure to keep class names and indices straight.  We recommend using them instead of manually making your own decision functions to operate on output classes.</p><p>As always, please feel free to comment or e-mail us with questions or ideas.</p></p>

<br>


<br>

]]></content>
  </entry>
  
</feed>
