<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Basics | PRT Blog]]></title>
  <link href="http://newfolder.github.io/blog/categories/basics/atom.xml" rel="self"/>
  <link href="http://newfolder.github.io/"/>
  <updated>2013-06-24T09:10:52-04:00</updated>
  <id>http://newfolder.github.io/</id>
  <author>
    <name><![CDATA[Kenneth Morton and Peter Torrione]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Combining Actions]]></title>
    <link href="http://newfolder.github.io/blog/2013/02/11/combining-actions/"/>
    <updated>2013-02-11T13:46:00-05:00</updated>
    <id>http://newfolder.github.io/blog/2013/02/11/combining-actions</id>
    <content type="html"><![CDATA[<p>Hi!  Today I'd like to talk about how you can use the PRT to combine actions together to form algorithms.  This is an important and powerful tool in the PRT, and understanding it can solve a lot of headaches for you.</p>


<!--/introduction-->


<h2>Contents</h2>


<div><ul><li><a href="#1">An Example</a></li><li><a href="#5">The Problem</a></li><li><a href="#9">Combining Actions into Algorithms</a></li><li><a href="#13">Using Algorithms</a></li></ul></div>


<h2>An Example<a name="1"></a></h2>


<p>Let's start with a concrete example.  Say we want to classify some very high dimensional data.  We'll start with the following:</p>


<pre class="codeinput">nFeatures = 200;
ds = prtDataGenUnimodal;
xNoise = randn(ds.nObservations,nFeatures);
ds.X = cat(2,ds.X,xNoise); <span class="comment">%add nFeatures meaningless features</span>
</pre>


<p>If we try and classify this with a GLRT, for example, we're going to run into trouble, since there are more features than there are observations, so we can't generate a full-rank covariance structure.  For example, using the prtAction prtClassGlrt, we might write this:</p>


<pre class="codeinput">glrt = prtClassGlrt;
glrt = glrt.train(ds);
<span class="keyword">try</span>
   yOut = glrt.run(ds);  <span class="comment">%This causes errors</span>
<span class="keyword">catch</span> ME
    disp(<span class="string">'Error encountered:'</span>)
    disp(ME);
<span class="keyword">end</span>
</pre>


<pre class="codeoutput">Warning: Covariance matrix is not positive definite. This may cause errors.
Consider modifying "covarianceStructure". 
Warning: Covariance matrix is not positive definite. This may cause errors.
Consider modifying "covarianceStructure". 
Error encountered:
  MException

  Properties:
    identifier: 'prtRvUtilMvnLogPdf:BadCovariance'
       message: 'SIGMA must be symmetric and positive definite.'
         cause: {0x1 cell}
         stack: [9x1 struct]


</pre>


<p>We can always use dimension-reduction techniques to reduce the number of features in our data set, and then evaluate performance.  For example:</p>


<pre class="codeinput">pca = prtPreProcPca(<span class="string">'nComponents'</span>,2);
pca = pca.train(ds);
dsPca = pca.run(ds);
plot(dsPca);
</pre>


<p><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_01.png" alt=""> <p>Now we can evaluate our GLRT on the dsPca:</p><pre class="codeinput">glrt = prtClassGlrt;
yOutKfolds = glrt.kfolds(dsPca,10);
[pf,pd] = prtScoreRoc(yOutKfolds);
h = plot(pf,pd);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
title(<span class="string">&lsquo;Example GLRT ROC Curve (Running on PCA Features)&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_02.png" alt=""> <h2>The Problem<a name="5"></a></h2><p>There&rsquo;s a problem in the above, though.  Even though we cross-validated the GLRT using 3 random folds, we didn&rsquo;t do the same thing with the PCA. This is technically not fair, since the PCA part of the algorithm was trained using all the data.</p><p>Maybe we can get around this like so:</p><pre class="codeinput">pca = prtPreProcPca(<span class="string">&lsquo;nComponents&rsquo;</span>,2);
dsPca = pca.kfolds(ds,10);
</pre><p>But now, when we do:</p><pre class="codeinput">glrt = prtClassGlrt;
yOutKfolds = glrt.kfolds(dsPca,10);
[pf,pd] = prtScoreRoc(yOutKfolds);
h = plot(pf,pd);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
title(<span class="string">&lsquo;This is no good&hellip;&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_03.png" alt=""> <p>We have a problem!  At every fold, we learn a unique set of PCA loadings. Since PCA loadings have arbitrary sign (+/&ndash;), the outputs across all these folds will overlap!</p><pre class="codeinput">plot(dsPca)
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_04.png" alt=""> <p>The underlying problem is that there&rsquo;s no guarantee that the folds used for PCA and GLRT evaluation were the same.  We can get around <b>that</b> if we specified the folds, and wrote our own cross-validate specifically for this new process we&rsquo;ve made, but suddenly this is getting complicated.</p><p>And what if we had an even more complicated process, including other pre-processing streams, feature selection, classifiers and decision-makers?  Suddenly our code is going to be a mess!</p><h2>Combining Actions into Algorithms<a name="9"></a></h2><p>At the heart of the problem outlined above is that the PCA and GLRT parts of our process weren&rsquo;t considered as two parts of the same process &ndash; they were two separate variables, and the PRT and MATLAB didn&rsquo;t know that they should work together.</p><p>Since this problem is so common, the PRT provides an easy way to combine each individual part of a process (prtActions) into one big process (a prtAlgorithm).  This is easily done using the &ldquo;+&rdquo; operator:</p><pre class="codeinput">pcaGlrt = prtPreProcPca(<span class="string">&lsquo;nComponents&rsquo;</span>,2) + prtClassGlrt;
</pre><p>If you&rsquo;re not used to object oriented programming, the above might look a little weird.  But it&rsquo;s straightforward &ndash; we&rsquo;ve defined &ldquo;plus&rdquo; (&ldquo;+&rdquo;) for prtActions (e.g., prtPreProcPca) to mean &ldquo;Combine these into one object, where that object will perform each action in sequence from left to right&rdquo;.  Technically this returns a special kind of prtAction, called a prtAlgorithm.  That&rsquo;s just the date type we use to store a bunch of actions.  You can see that here:</p><pre class="codeinput">disp(pcaGlrt)
</pre><pre class="codeoutput">  prtAlgorithm</p>

<p>  Properties:</p>

<pre><code>                name: 'PRT Algorithm'
    nameAbbreviation: 'ALGO'
        isSupervised: 1
isCrossValidateValid: 1
          actionCell: {2x1 cell}
  connectivityMatrix: [4x4 logical]
      verboseStorage: 1
     showProgressBar: 1
           isTrained: 0
      dataSetSummary: []
             dataSet: []
            userData: [1x1 struct]
</code></pre>

<p></pre><p>You can visualize the structure of the algorithm using PLOT:</p><pre class="codeinput">plot(pcaGlrt)
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_05.png" alt=""> <p>You can combine any number of prtActions into an algorithm like this, so, although its silly, this is technically a valid command:</p><pre class="codeinput">sillyAlgo = prtPreProcZmuv + prtPreProcHistEq + prtPreProcPca + prtClassGlrt;
plot(sillyAlgo)
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_06.png" alt=""> <h2>Using Algorithms<a name="13"></a></h2><p>So we&rsquo;ve made a prtAlgorithm.  Now what?  Well, anything you can do to a prtAction, you can do with a prtAlgorithm.  What does that mean?  Methods like plot, kfolds, and crossValidate all work exactly the same as they do with regular prtActions.  And they make your life much simpler than what we had to do above:</p><pre class="codeinput">pcaGlrt = prtPreProcPca(<span class="string">&lsquo;nComponents&rsquo;</span>,2) + prtClassGlrt;
yOutKfolds = pcaGlrt.kfolds(ds,10);
[pf,pd] = prtScoreRoc(yOutKfolds);
h = plot(pf,pd);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
title(<span class="string">&lsquo;ROC Curve for a prtAlgorithm (PCA + GLRT)&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_combiningActions_07.png" alt=""> <p>The results in the ROC curve above were generated using 10-folds cross-validation on the combination of PCA and GLRT.  At each fold, 9/10ths of the data were used to train the PCA and GLRT, and 1/10th was used for evaluation.</p><p>prtAlgorithms are a very powerful tool for pattern recognition, and we hope this blog post helps clear up how to make and use them!</p><p>Let us know if you have any questions or comments.</p></p>

<br>


<br>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Introduction to the PRT with MNIST]]></title>
    <link href="http://newfolder.github.io/blog/2013/01/21/introduction-to-the-prt/"/>
    <updated>2013-01-21T18:58:00-05:00</updated>
    <id>http://newfolder.github.io/blog/2013/01/21/introduction-to-the-prt</id>
    <content type="html"><![CDATA[<p>The MNIST Database (<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>) is a very well-known machine learning dataset consisting of a few thousand instances of handwritten digits from 0-9.  MNIST is actually a subset of a larger NIST database, but the authors (see the linked page above) were kind enough to do some basic pre-processing of MNIST for us.  MNIST was for a long time very widely used in the ML literature as an example of an easy to use real data set to evaluate new ideas.</p>




<!--/introduction-->


<h2>Contents</h2>


<div><ul><li><a href="#1">Obtaining, Loading, and Visualizing MNIST Data</a></li><li><a href="#5">Classification: PLSDA</a></li><li><a href="#8">Classification: SVM</a></li><li><a href="#12">Exploring the Results</a></li></ul></div>


<h2>Obtaining, Loading, and Visualizing MNIST Data<a name="1"></a></h2>


<p>Tools to read in the MNIST database into the PRT are available in the newest PRT version.  To conserve bandwidth, the actual MNIST data isn&#8217;t included in the PRT (it would kill our subversion servers).  Instead you can download the MNIST database from the website linked above.  Once you&#8217;ve downloaded it, extract the data into:</p>


<pre class="codeinput">fullfile(prtRoot,<span class="string">'dataGen'</span>,<span class="string">'dataStorage'</span>,<span class="string">'MNIST'</span>) <span class="comment">%MATLAB command will tell you the directory</span>
</pre>


<pre class="codeoutput">
ans =

C:\Users\Pete\Documents\MATLAB\toolboxes\nfPrt\dataGen\dataStorage\MNIST

</pre>


<p>For example, on my system:</p>


<pre class="codeinput">ls(fullfile(prtRoot,<span class="string">'dataGen'</span>,<span class="string">'dataStorage'</span>,<span class="string">'MNIST'</span>))
</pre>


<pre class="codeoutput">
.                        t10k-labels.idx1-ubyte   
..                       train-images.idx3-ubyte  
t10k-images.idx3-ubyte   train-labels.idx1-ubyte  

</pre>


<p>Once the MNIST files are in the right place, execute the PRT command:</p>


<pre class="codeinput">dsTrain = prtDataGenMnist;
</pre>


<p>to extract the data.  ( Note, prtDataGenMnist makes use of a M-file function called readMNIST by Siddharth Hegde.  It&#8217;s available from: <a href="http://www.mathworks.com/matlabcentral/fileexchange/27675-read-digits-and-labels-from-mnist-database">http://www.mathworks.com/matlabcentral/fileexchange/27675-read-digits-and-labels-from-mnist-database</a> ).</p>


<p>Once loaded, we can use a number of different tools to visualize the data.  First, let&#8217;s visualize the data as images.  We know that the images are size 28x28, but since the prtDataSetClass object expects each observation to correspond to a 1xN vector, we store all the 28x28 images as 1x784 vectors.</p>


<pre class="codeinput">imageSize = [28 28];

<span class="keyword">for</span> i = 1:9;
    subplot(3,3,i);
    x = dsTrain.getX(i); <span class="comment">%1x784</span>
    y = dsTrain.getY(i);
    imagesc(reshape(x,imageSize));
    colormap <span class="string">gray</span>;
    title(sprintf(<span class="string">'MNIST; Digit = %d'</span>,y));
<span class="keyword">end</span>
</pre>


<p><img vspace="5" hspace="5" src="/images/testBlog_01.png" alt=""> <h2>Classification: PLSDA<a name="5"></a></h2><p>What kinds of classification approaches can we apply to this data set? We need to satisfy a few requirements: 1) M-Ary classification, 2) Relatively fast, 3) Relatively insensitive to a large number of dimensions (784 dimensional vectors). One particularly fast, linear approach to classification that&#8217;s relatively insensitive to the number of feature dimensions is partial-least squares discriminant analysis, implemented in the PRT as prtClassPLSDA.  With only a few lines of code we can implement and evaluate a PLSDA classifier on the MNIST data, for example:</p><pre class="codeinput">algo = prtClassPlsda(<span class="string">&lsquo;nComponents&rsquo;</span>,20) + prtDecisionMap; <span class="comment">%we include the Max-A-Posteriori classifier</span>
yOut = algo.kfolds(dsTrain,3); <span class="comment">%3 folds x-val</span>
pc = prtScorePercentCorrect(yOut);
subplot(1,1,1);
prtScoreConfusionMatrix(yOut);
title(sprintf(<span class="string">&lsquo;3-Fold X-Val PLSDA on 10,000 MNIST Database Train Samples; %.0f%% Correct&rsquo;</span>,pc*100));
</pre><img vspace="5" hspace="5" src="/images/testBlog_02.png" alt=""> <p>This basic example results in the above figure, where we see we&#8217;ve achieved about 84% correct classification, and we can analyze confusions between digits.  For example, the digits 4 and 9 are often confused, which seems intuitive since they look relatively similar.</p><p>We can also evaluate the PLSDA classifier trained on 10,000 training points and evaluated on the MNIST testing data.  To do so we first load the testing data, then train our classifier and evaluate it:</p></p>

<pre class="codeinput">dsTest = prtDataGenMnistTest;
algo = algo.train(dsTrain);
yOut = algo.run(dsTest);
pc = prtScorePercentCorrect(yOut);
subplot(1,1,1);
prtScoreConfusionMatrix(yOut);
title(sprintf(<span class="string">'PLSDA on 10,000 MNIST Database Test Samples; %.0f%% Correct'</span>,pc*100));
</pre>


<p><img vspace="5" hspace="5" src="/images/testBlog_03.png" alt=""> <p>Performance on the test set is relatively similar to performance in cross-validation as can be seen above.</p><p>Overall, our performance is hovering around a 15% error rate.  That&#8217;s roughly comparable to the 12% error reported in LeCun et al., 1988, and here we&#8217;re not using a lot of the techniques in the Le Cun paper (and this is with barely 5 lines of code!).</p><h2>Classification: SVM<a name="8"></a></h2><p>As the results on <a href="http://yann.lecun.com/exdb/mnist/"><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></a> illustrate, other approaches to digit classification have done much better than our simple PLSDA classifier.  We can use the PRT to apply more complicated classifiers to the same data also, and hopefully decrease our error rate.</p><p>For example, consider a simple application of an SVM classifier to the digit recognition problem.  Since the SVM is not an M-ary classification technique, we need to wrap our SVM in a One-Vs-All classifier to perform M-ary classification (Warning: the following code took about 30 minutes to run on my laptop):</p><pre class="codeinput">marySvm = prtPreProcZmuv + prtClassBinaryToMaryOneVsAll(<span class="string">&lsquo;baseClassifier&rsquo;</span>,prtClassLibSvm) + prtDecisionMap;
yOut = marySvm.kfolds(dsTrain,3);
pc = prtScorePercentCorrect(yOut);
subplot(1,1,1);
prtScoreConfusionMatrix(yOut);
title(sprintf(<span class="string">&lsquo;3-Fold X-Val SVM on 10,000 MNIST Database Train Samples; %.0f%% Correct&rsquo;</span>,pc*100));
</pre><pre class="codeoutput">Warning: Non-finite or zero standard deviation encountered.  Replacing invalid
standard deviations with 1
Warning: Non-finite or zero standard deviation encountered.  Replacing invalid
standard deviations with 1
Warning: Non-finite or zero standard deviation encountered.  Replacing invalid
standard deviations with 1
</pre><img vspace="5" hspace="5" src="/images/testBlog_04.png" alt=""> <p>As can be seen above, the SVM achieves an error rate of 5% on this data set!  That&#8217;s a significant improvement over the PLSDA classification we showed before.  Similarly to with PLSDA, we can also evaluate the algorithm on completely separate testing data:</p></p>

<pre class="codeinput">marySvm = marySvm.train(dsTrain);
yOut = marySvm.run(dsTest);
pc = prtScorePercentCorrect(yOut);
subplot(1,1,1);
prtScoreConfusionMatrix(yOut);
title(sprintf(<span class="string">'PLSDA on 10,000 MNIST Database Test Samples; %.0f%% Correct'</span>,pc*100));
</pre>


<pre class="codeoutput">Warning: Non-finite or zero standard deviation encountered.  Replacing invalid
standard deviations with 1 
</pre>


<p><img vspace="5" hspace="5" src="/images/testBlog_05.png" alt=""> <p>And we see that performance is comparable to the cross-validated results. (Note that more advanced applications of SVM classifiers can do even better than the results reported here &#8211; Le Cun et al., 1998 reported 1.4% error rates with an SVM and some additional processing).</p><h2>Exploring the Results<a name="12"></a></h2><p>If we wanted to improve classification, we could optimize over the SVM parameters, kernel, pre-processing etc.  But before we did that, it might be instructive to investigate what digits the SVM classifier is mislabeling, and see if some of them seem like reasonable mistakes to make.  The following code will pick 9 instances where the SVM output label was different from the actual data label, and plot them in a subplot.</p></p>

<pre class="codeinput">incorrect = find(yOut.getX ~= yOut.getY);
yOutTestMisLabeled = yOut.retainObservations(incorrect);
dsTestMisLabeled = dsTest.retainObservations(incorrect);
<span class="keyword">for</span> i = 1:9; <span class="comment">%dsTestMisLabeled.nObservations;</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;randWrong = ceil(rand*dsTestMisLabeled.nObservations); <span class="comment">%pick a random wrong element</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subplot(3,3,i);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x = dsTestMisLabeled.getX(randWrong);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img = reshape(x,imageSize);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;imagesc(img);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;colormap <span class="string">gray</span>;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
title(sprintf(<span class="string">'Actual: %d; SVM Label: %d'</span>,yOutTestMisLabeled.getY(randWrong),yOutTestMisLabeled.getX(randWrong)));
<span class="keyword">end</span>
</pre>


<p><img vspace="5" hspace="5" src="/images/testBlog_06.png" alt=""> <p>Visual inspection of these mistakes illustrate some of the causes of confusions in the SVM.  For example, highly slanted digits are often mis-labeled.  Mitigating some of these mistakes may require significantly more than simply optimizing SVM parameters!</p><p>Interested readers can refer to a large body of literature that has previously investigated this data set (<a href="http://yann.lecun.com/exdb/mnist/"><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></a>) for tips, tricks, and ideas for further improving performance on this data set.  One particularly exciting recent advance is based on Hinton&#8217;s deep learning networks, which enables very efficient learning on the MNIST database <a href="www.cs.toronto.edu/~hinton/science.pdf">www.cs.toronto.edu/~hinton/science.pdf</a>).</p><p>We hope this example shows how quickly you can get from data to results with the PRT.  Please let us know if you have comments or questions!</p></p>

<br>


<br>

]]></content>
  </entry>
  
</feed>
